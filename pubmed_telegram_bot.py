import os
import time
import requests
from bs4 import BeautifulSoup

# ===================== –ù–ê–°–¢–†–û–ô–ö–ò =====================

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

# –†—É—Å—Å–∫–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∂—É—Ä–Ω–∞–ª—ã (—Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π)
SOURCES = [
    {
        "name": "–ü—É–ª—å–º–æ–Ω–æ–ª–æ–≥–∏—è",
        "url": "https://journal.pulmonology.ru/pulm/issue/current",
        "article_selector": "div.title a",
        "content_selector": "div.article-summary, div.abstract, section.abstract",
    },
    {
        "name": "Russian Journal of Allergy",
        "url": "https://rusalljournal.ru/raj/issue/current",
        "article_selector": "div.title a",
        "content_selector": "div.article-summary, div.abstract, section.abstract",
    },
]

HEADERS = {"User-Agent": "Mozilla/5.0"}

# ======================================================


def send_to_telegram(text: str):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram"""

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"

    payload = {
        "chat_id": TELEGRAM_CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False,
    }

    r = requests.post(url, json=payload, timeout=20)
    print("Telegram:", r.text)



def get_article_text(link: str, selector: str) -> str:
    """–ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∏–ª–∏ —Å—Ç–∞—Ç—å–∏"""

    try:
        r = requests.get(link, headers=HEADERS, timeout=20)
        soup = BeautifulSoup(r.text, "html.parser")

        blocks = soup.select(selector)

        if not blocks:
            return "–¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω."

        text = "\n".join(b.get_text(" ", strip=True) for b in blocks)

        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É –¥–ª—è Telegram (–¥–æ ~3500 —Å–∏–º–≤–æ–ª–æ–≤)
        return text[:3500]

    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å—Ç–∞—Ç—å–∏:", e)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏."



def get_latest_article_from_source(source):
    """–ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∂—É—Ä–Ω–∞–ª–∞ –∏ –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é —Ä–µ–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é"""

    try:
        r = requests.get(source["url"], headers=HEADERS, timeout=20)
        soup = BeautifulSoup(r.text, "html.parser")

        links = soup.select(source["article_selector"])

        if not links:
            return None

        article_link = links[0]

        title = article_link.get_text(strip=True)
        link = article_link.get("href")

        if not title or not link:
            return None

        # –µ—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è ‚Äî –¥–µ–ª–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—É—é
        if link.startswith("/"):
            base = source["url"].split("/", 3)[:3]
            base_url = "/".join(base)
            link = base_url + link

        # –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏
        content = get_article_text(link, source["content_selector"])

        return title, link, source["name"], content

    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞", source["name"], e)
        return None



def main():
    """–ü–æ–ª—É—á–∞–µ–º –ø–æ –æ–¥–Ω–æ–π —Å—Ç–∞—Ç—å–µ –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∂—É—Ä–Ω–∞–ª–∞"""

    sent_any = False

    for source in SOURCES:
        article = get_latest_article_from_source(source)

        if not article:
            continue

        title, link, source_name, content = article

        text = (
            f"ü©∫ <b>–ù–æ–≤–∞—è —Å—Ç–∞—Ç—å—è</b>\n\n"
            f"<b>{title}</b>\n\n"
            f"{content}\n\n"
            f"–ò—Å—Ç–æ—á–Ω–∏–∫: {source_name}\n"
            f"{link}"
        )

        send_to_telegram(text)
        sent_any = True

        time.sleep(2)

    if not sent_any:
        send_to_telegram("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–æ–≤—ã–µ —Å—Ç–∞—Ç—å–∏ –≤ —Ä—É—Å—Å–∫–∏—Ö –∂—É—Ä–Ω–∞–ª–∞—Ö")


if __name__ == "__main__":
    main()
